{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring of MCQ and FCQ from Amy's data\n",
    "We will read in raw response data, combine with the WCQ and FCQ questions, and score each. This will result in a $\\log(k)$ score for each participant for the WCQ and the FCQ.\n",
    "\n",
    "WCQ = Lim & Bruce.\n",
    "\n",
    "FCQ = Hendrickson et al (2015)\n",
    "\n",
    "Information about use of `pm.Data` containers can be found here https://docs.pymc.io/notebooks/data_container.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Black autoformatter with: pip install nb-black\n",
    "%load_ext lab_black\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 12345\n",
    "\n",
    "# Define sampler options\n",
    "sample_options = {\n",
    "    \"tune\": 2000,\n",
    "    \"draws\": 2000,\n",
    "    \"chains\": 2,\n",
    "    \"cores\": 2,\n",
    "    \"nuts_kwargs\": {\"target_accept\": 0.95},\n",
    "    \"random_seed\": SEED,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discount_func(ax, data, trace):\n",
    "    delays = np.linspace(0, np.max(data.DB.values), 1000)\n",
    "\n",
    "    # plot posterior mean\n",
    "    k = np.exp(np.mean(trace[\"logk\"]))\n",
    "    ax.plot(delays, discount_function(delays, k), lw=4)\n",
    "\n",
    "    # plot 95% region\n",
    "    p = np.percentile(np.exp(trace[\"logk\"]), [5 / 2, 100 - (5 / 2)])\n",
    "    ax.fill_between(\n",
    "        delays,\n",
    "        discount_function(delays, p[0]),\n",
    "        discount_function(delays, p[1]),\n",
    "        alpha=0.2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    D = data[\"R\"] == 1\n",
    "    I = data[\"R\"] == 0\n",
    "\n",
    "    if np.sum(D) > 0:\n",
    "        ax.scatter(\n",
    "            x=data[\"DB\"][D],\n",
    "            y=data[\"RA\"][D] / data[\"RB\"][D],\n",
    "            c=\"k\",\n",
    "            edgecolors=\"k\",\n",
    "            label=\"chose delayed prospect\",\n",
    "        )\n",
    "    if np.sum(I) > 0:\n",
    "        ax.scatter(\n",
    "            x=data[\"DB\"][I],\n",
    "            y=data[\"RA\"][I] / data[\"RB\"][I],\n",
    "            c=\"w\",\n",
    "            edgecolors=\"k\",\n",
    "            label=\"chose immediate prospect\",\n",
    "        )\n",
    "\n",
    "    ax.set(\n",
    "        xlabel=\"DB\", ylabel=\"RA/RB\", ylim=[0, 1], xlim=[0, 1.05 * np.max(data[\"DB\"])]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_questions(data, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    ax.scatter(x=data[\"DB\"], y=data[\"RA\"] / data[\"RB\"])\n",
    "    ax.set(\n",
    "        xlabel=\"DB\", ylabel=\"RA/RB\", ylim=[0, 1], xlim=[0, 1.05 * np.max(data[\"DB\"])]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../02 processed data/study2_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in question values from WCQ and FCQ\n",
    "We need the delay and reward values for the WCQ and the FCQ. We will read these in from `.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcq = pd.read_csv(\"study2_wcq.csv\")\n",
    "\n",
    "# IMPORTANT: Ensure rows are sorted by `order`\n",
    "wcq = wcq.sort_values(by=\"order\")\n",
    "\n",
    "plot_questions(wcq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcq = pd.read_csv(\"study2_fcq.csv\")\n",
    "\n",
    "# IMPORTANT: Ensure rows are sorted by `order`\n",
    "fcq = fcq.sort_values(by=\"order\")\n",
    "\n",
    "plot_questions(fcq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction functions\n",
    "These functions will get the responses from the raw data file, and combine them together with the MCQ or WCQ questions we imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_WCQ_data(data, row):\n",
    "    id = data.iloc[row, :].URN\n",
    "    df = wcq\n",
    "    df[\"R\"] = (data.iloc[row, data.columns.str.contains(\"WCQ\")] - 1).values\n",
    "    # force to be numeric\n",
    "    df = df.astype(float)\n",
    "    return (id, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_FCQ_data(data, row):\n",
    "    id = data.iloc[row, :].URN\n",
    "    df = fcq\n",
    "    df[\"R\"] = (data.iloc[row, data.columns.str.contains(\"FCQ\")] - 1).values\n",
    "    # force to be numeric\n",
    "    df = df.astype(float)\n",
    "    return (id, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build our Bayesian model\n",
    "We will use the `pm.Data` class so that we can build one model only, then use it multiple times to fit data from each participant seperately. This should make things more efficient, avoiding building the same model hundreds of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def V(reward, delay, logk):\n",
    "    \"\"\"Calculate the present subjective value of a given prospect\"\"\"\n",
    "    k = pm.math.exp(logk)\n",
    "    return reward * discount_function(delay, k)\n",
    "\n",
    "\n",
    "def discount_function(delay, k):\n",
    "    \"\"\" Hyperbolic discount function \"\"\"\n",
    "    return 1 / (1.0 + (k * delay))\n",
    "\n",
    "\n",
    "def Φ(VA, VB, ϵ=0.01):\n",
    "    \"\"\"Psychometric function which converts the decision variable (VB-VA)\n",
    "    into a reponse probability. Output corresponds to probability of choosing\n",
    "    the delayed reward (option B).\"\"\"\n",
    "    return ϵ + (1.0 - 2.0 * ϵ) * (1 / (1 + pm.math.exp(-1.7 * (VB - VA))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data):\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # data nodes\n",
    "        RA = pm.Data(\"RA\", data.RA.values)\n",
    "        RB = pm.Data(\"RB\", data.RB.values)\n",
    "        DB = pm.Data(\"DB\", data.DB.values)\n",
    "        R = pm.Data(\"R\", data.R.values)\n",
    "\n",
    "        # prior\n",
    "        logk = pm.Normal(\"logk\", mu=-3, sd=2)\n",
    "\n",
    "        # response probability\n",
    "        P = pm.Deterministic(\"P\", Φ(RA, V(RB, DB, logk)))\n",
    "\n",
    "        # likelihood\n",
    "        response = pm.Bernoulli(\"response\", p=P, observed=R)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_participant(data, plot=False):\n",
    "    \"\"\"Our core function to score a participant\"\"\"\n",
    "\n",
    "    with model:\n",
    "        # set the data\n",
    "        pm.set_data({\"RA\": data.RA, \"RB\": data.RB, \"DB\": data.DB, \"R\": data.R})\n",
    "\n",
    "        # do the sampling\n",
    "        trace = pm.sample(**sample_options)\n",
    "\n",
    "    logk_mean = np.mean(trace[\"logk\"])\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        plot_data(data, ax=ax)\n",
    "        plot_discount_func(ax, data, trace)\n",
    "        plt.show()\n",
    "\n",
    "    return logk_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score FCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to build the model we need some example data\n",
    "participant = 0\n",
    "temp_trial_data = extract_FCQ_data(data, participant)[1]\n",
    "temp_trial_data\n",
    "\n",
    "# Now build the model at last\n",
    "model = build_model(temp_trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_participants = data.shape[0]\n",
    "\n",
    "should_plot = False\n",
    "\n",
    "pid = []\n",
    "logk_fcq = []\n",
    "\n",
    "for i in range(n_participants):\n",
    "    id_num, fcq_trial_data = extract_FCQ_data(data, i)\n",
    "    logk_fcq_value = score_participant(fcq_trial_data, plot=should_plot)\n",
    "    logk_fcq.append(logk_fcq_value)\n",
    "    pid.append(id_num)\n",
    "\n",
    "results = pd.DataFrame({\"URN\": pid, \"logk_fcq\": logk_fcq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with original data file\n",
    "data = pd.merge(data, results, on=\"URN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score WCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to build the model we need some example data\n",
    "participant = 0\n",
    "temp_trial_data = extract_WCQ_data(data, participant)[1]\n",
    "temp_trial_data\n",
    "\n",
    "# Now build the model at last\n",
    "model = build_model(temp_trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_participants = data.shape[0]\n",
    "\n",
    "should_plot = False\n",
    "\n",
    "pid = []\n",
    "logk_wcq = []\n",
    "\n",
    "for i in range(n_participants):\n",
    "    id_num, wcq_trial_data = extract_WCQ_data(data, i)\n",
    "    print(id_num)\n",
    "    logk_wcq_value = score_participant(wcq_trial_data, plot=should_plot)\n",
    "    logk_wcq.append(logk_wcq_value)\n",
    "    pid.append(id_num)\n",
    "\n",
    "results = pd.DataFrame({\"URN\": pid, \"logk_wcq\": logk_wcq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with original data file\n",
    "data = pd.merge(data, results, on=\"URN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove raw data columns, no longer needed\n",
    "data = data[data.columns.drop(list(data.filter(regex=\"WCQ\")))]\n",
    "data = data[data.columns.drop(list(data.filter(regex=\"FCQ\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "data.to_csv(\"study2_final_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharex=False)\n",
    "\n",
    "bins = 21\n",
    "\n",
    "ax[0].hist(logk_wcq, bins)\n",
    "ax[0].set(\n",
    "    xlabel=\"$\\ln(k)$ [k in units of days$^{-1}$]\", ylabel=\"frequency\", title=\"WCQ\"\n",
    ")\n",
    "\n",
    "ax[1].hist(logk_fcq, bins)\n",
    "ax[1].set(\n",
    "    xlabel=\"$\\ln(k)$ [k in units of hours$^{-1}$]\", ylabel=\"frequency\", title=\"FCQ\"\n",
    ")\n",
    "\n",
    "# increased space between rows\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "plt.savefig(\"../study2_fit_histograms.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
